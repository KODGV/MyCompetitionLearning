{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#import dask.dataframe as dd\n",
    "#from dask.multiprocessing import get\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils import *\n",
    "#from utils2 import *\n",
    "#from utils3 import *\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "#from tqdm import tqdm\n",
    "#test\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "\n",
    "USE_KFOLD = True\n",
    "\n",
    "data_path = './input/'\n",
    "\n",
    "####################################读入文件####################################################\n",
    "\n",
    "\n",
    "def astype(x,t):\n",
    "    try:\n",
    "        return t(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def have_0(x):\n",
    "    try:\n",
    "        r = x.split('.')[1][-1]\n",
    "        return 0 if r=='0' else 1\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "str_dict = {'1_total_fee': 'str',\n",
    " '2_total_fee': 'str',\n",
    " '3_total_fee': 'str',\n",
    " '4_total_fee': 'str',\n",
    " 'pay_num': 'str',\n",
    " }\n",
    "\n",
    "\n",
    "have_0_c = ['1_total_fee',\n",
    "'2_total_fee',\n",
    "'3_total_fee',\n",
    "'4_total_fee',\n",
    "'pay_num']\n",
    "\n",
    "def deal(data):\n",
    "    for c in have_0_c:\n",
    "        data['have_0_{}'.format(c)] = data[c].apply(have_0)\n",
    "        try:\n",
    "            data[c] = data[c].astype(float)\n",
    "        except:\n",
    "            pass\n",
    "    data['2_total_fee'] = data['2_total_fee'].apply(lambda x: astype(x,float))\n",
    "    data['3_total_fee'] = data['3_total_fee'].apply(lambda x: astype(x,float))\n",
    "    data['age'] = data['age'].apply(lambda x: astype(x,int))\n",
    "    data['gender'] = data['gender'].apply(lambda x: astype(x,int))\n",
    "    data.loc[data['age']==0,'age'] = np.nan\n",
    "    data.loc[data['1_total_fee'] < 0, '1_total_fee'] = np.nan\n",
    "    data.loc[data['2_total_fee'] < 0, '2_total_fee'] = np.nan\n",
    "    data.loc[data['3_total_fee'] < 0, '3_total_fee'] = np.nan\n",
    "    data.loc[data['4_total_fee'] < 0, '4_total_fee'] = np.nan\n",
    "    for c in [\n",
    "    '1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee',\n",
    "    'month_traffic', 'last_month_traffic', 'local_trafffic_month',\n",
    "    'local_caller_time', 'service1_caller_time', 'service2_caller_time',\n",
    "    'many_over_bill', 'contract_type', 'contract_time', 'pay_num', ]:\n",
    "        data[c] = data[c].round(4)\n",
    "    data['is_duplicated'] =data.duplicated(subset=['1_total_fee','2_total_fee','3_total_fee',\n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],keep=False)\n",
    "    return data\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv',dtype=str_dict)\n",
    "train = deal(train)\n",
    "train.drop_duplicates(subset = ['1_total_fee','2_total_fee','3_total_fee',\n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({\"A\": [4,3,5,3,2,1]})\n",
    "df['B']=df.duplicated(subset='A', keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='A',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A      B\n",
       "0  4  False\n",
       "1  3   True\n",
       "2  5  False\n",
       "4  2  False\n",
       "5  1  False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3          True\n",
       "4         False\n",
       "5         False\n",
       "6         False\n",
       "7         False\n",
       "8          True\n",
       "9         False\n",
       "10        False\n",
       "11        False\n",
       "12        False\n",
       "13        False\n",
       "14        False\n",
       "15         True\n",
       "16        False\n",
       "17        False\n",
       "18        False\n",
       "19        False\n",
       "20         True\n",
       "21        False\n",
       "22        False\n",
       "23         True\n",
       "24         True\n",
       "25         True\n",
       "26        False\n",
       "27        False\n",
       "28        False\n",
       "29        False\n",
       "          ...  \n",
       "743953    False\n",
       "743955    False\n",
       "743956    False\n",
       "743958    False\n",
       "743959    False\n",
       "743960    False\n",
       "743961    False\n",
       "743962    False\n",
       "743964    False\n",
       "743965    False\n",
       "743966    False\n",
       "743967    False\n",
       "743968    False\n",
       "743969    False\n",
       "743970    False\n",
       "743971    False\n",
       "743972    False\n",
       "743974    False\n",
       "743975    False\n",
       "743976    False\n",
       "743977    False\n",
       "743979    False\n",
       "743980    False\n",
       "743981    False\n",
       "743982    False\n",
       "743983    False\n",
       "743984    False\n",
       "743986    False\n",
       "743988    False\n",
       "743989    False\n",
       "Name: is_duplicated, Length: 665130, dtype: bool"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.is_duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (20,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "665130\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error,mean_absolute_error, f1_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold,GroupKFold\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from utils import *\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "#test\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "USE_KFOLD = True\n",
    "\n",
    "data_path = './input/'\n",
    "\n",
    "####################################读入文件####################################################\n",
    "#要准备hzs的两个get most文件\n",
    "def astype(x,t):\n",
    "    try:\n",
    "        return t(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def have_0(x):\n",
    "    try:\n",
    "        r = x.split('.')[1][-1]\n",
    "        return 0 if r=='0' else 1\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "str_dict = {'1_total_fee': 'str',\n",
    " '2_total_fee': 'str',\n",
    " '3_total_fee': 'str',\n",
    " '4_total_fee': 'str',\n",
    " 'pay_num': 'str',\n",
    " }\n",
    "\n",
    "\n",
    "have_0_c = ['1_total_fee',\n",
    "'2_total_fee',\n",
    "'3_total_fee',\n",
    "'4_total_fee',\n",
    "'pay_num']\n",
    "\n",
    "def deal(data):\n",
    "    for c in have_0_c:\n",
    "        data['have_0_{}'.format(c)] = data[c].apply(have_0)\n",
    "        try:\n",
    "            data[c] = data[c].astype(float)\n",
    "        except:\n",
    "            pass\n",
    "    data['2_total_fee'] = data['2_total_fee'].apply(lambda x: astype(x,float))\n",
    "    data['3_total_fee'] = data['3_total_fee'].apply(lambda x: astype(x,float))\n",
    "    data['age'] = data['age'].apply(lambda x: astype(x,int))\n",
    "    data['gender'] = data['gender'].apply(lambda x: astype(x,int))\n",
    "    data.loc[data['age']==0,'age'] = np.nan\n",
    "    data.loc[data['1_total_fee'] < 0, '1_total_fee'] = np.nan\n",
    "    data.loc[data['2_total_fee'] < 0, '2_total_fee'] = np.nan\n",
    "    data.loc[data['3_total_fee'] < 0, '3_total_fee'] = np.nan\n",
    "    data.loc[data['4_total_fee'] < 0, '4_total_fee'] = np.nan\n",
    "    for c in [\n",
    "    '1_total_fee', '2_total_fee', '3_total_fee', '4_total_fee',\n",
    "    'month_traffic', 'last_month_traffic', 'local_trafffic_month',\n",
    "    'local_caller_time', 'service1_caller_time', 'service2_caller_time',\n",
    "    'many_over_bill', 'contract_type', 'contract_time', 'pay_num', ]:\n",
    "        data[c] = data[c].round(4)\n",
    "    return data\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv',dtype=str_dict)\n",
    "train = deal(train)\n",
    "train.drop_duplicates(subset = ['1_total_fee','2_total_fee','3_total_fee',\n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],inplace=True)\n",
    "train = train[train['current_service'] != 999999]\n",
    "test = pd.read_csv(data_path + 'test.csv',dtype=str_dict)\n",
    "test = deal(test)\n",
    "\n",
    "train_old = pd.read_csv('./input/train_old.csv',dtype=str_dict)[:]\n",
    "train_old = deal(train_old)\n",
    "train_old.drop_duplicates(subset = ['1_total_fee','2_total_fee','3_total_fee',\n",
    " 'month_traffic','pay_times','last_month_traffic','service2_caller_time','age'],inplace=True)\n",
    "    \n",
    "\n",
    "\n",
    "print(len(train))\n",
    "\n",
    "\n",
    "label2current_service =dict(zip(range(0,len(set(train['current_service']))),sorted(list(set(train['current_service'])))))\n",
    "current_service2label =dict(zip(sorted(list(set(train['current_service']))),range(0,len(set(train['current_service'])))))\n",
    "print(len(label2current_service))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{89950166: 0,\n",
       " 89950167: 1,\n",
       " 89950168: 2,\n",
       " 90063345: 3,\n",
       " 90109916: 4,\n",
       " 90155946: 5,\n",
       " 99999825: 6,\n",
       " 99999826: 7,\n",
       " 99999827: 8,\n",
       " 99999828: 9,\n",
       " 99999830: 10}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_service2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=train[['former_complaint_fee','current_service']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>former_complaint_fee</th>\n",
       "      <th>current_service</th>\n",
       "      <th>mod</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>former_complaint_fee</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000849</td>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.038266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>current_service</th>\n",
       "      <td>-0.000849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.046337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mod</th>\n",
       "      <td>-0.000123</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.493107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>0.038266</td>\n",
       "      <td>0.046337</td>\n",
       "      <td>0.493107</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      former_complaint_fee  current_service       mod  \\\n",
       "former_complaint_fee              1.000000        -0.000849 -0.000123   \n",
       "current_service                  -0.000849         1.000000  0.018194   \n",
       "mod                              -0.000123         0.018194  1.000000   \n",
       "log                               0.038266         0.046337  0.493107   \n",
       "\n",
       "                           log  \n",
       "former_complaint_fee  0.038266  \n",
       "current_service       0.046337  \n",
       "mod                   0.493107  \n",
       "log                   1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t['mod']=round(t.former_complaint_fee%100)\n",
    "t['log']=np.log1p(t.former_complaint_fee)\n",
    "t.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.append(test).reset_index(drop = True)\n",
    "print(len(train))\n",
    "shape1 = len(train)\n",
    "#train['is_b'] = 1\n",
    "#train_old['is_b'] = 0      \n",
    "train = train.append(train_old).reset_index(drop = True)\n",
    "print(len(train))\n",
    "shape2 = len(train)\n",
    "\n",
    "get_most = pd.read_csv('Magic_Feature_Exclude_Old.csv')\n",
    "get_most2 = pd.read_csv('Magic_Feature_Include_Old.csv')\n",
    "\n",
    "####################################特征工程###################################################\n",
    "\n",
    "call_time = ['local_caller_time', 'service1_caller_time', 'service2_caller_time']\n",
    "traffic = ['month_traffic','last_month_traffic','local_trafffic_month']\n",
    "cat_cols = ['service_type','contract_type', 'net_service', 'gender', 'complaint_level',\n",
    "               #3              #9,8           #4             #3         #4           \n",
    "   'is_mix_service',  'many_over_bill', 'is_promise_low_consume',   #2    \n",
    "    ]\n",
    "continus_col = [\n",
    "    '1_total_fee', '2_total_fee', '3_total_fee',  '4_total_fee', 'pay_num','former_complaint_fee',\n",
    "    \n",
    "    'month_traffic', 'last_month_traffic', 'local_trafffic_month', \n",
    "    \n",
    "    'local_caller_time', 'service1_caller_time', 'service2_caller_time',\n",
    "    \n",
    "    'online_time','contract_time',  \n",
    "     \n",
    "    'pay_times', 'former_complaint_num'\n",
    "    ]\n",
    "def one_hot_encoder(train,column,n=100,nan_as_category=False):\n",
    "    tmp = train[column].value_counts().to_frame()\n",
    "    values = list(tmp[tmp[column]>n].index)\n",
    "    train.loc[train[column].isin(values),column+'N'] = train.loc[train[column].isin(values),column]\n",
    "    train =  pd.get_dummies(train, columns=[column+'N'], dummy_na=False)\n",
    "    return train\n",
    "#\n",
    "\n",
    "\n",
    "train['fea-min'] = train[[str(1+i) +'_total_fee' for i in range(4)]].min(axis = 1)\n",
    "\n",
    "for column in ['1_total_fee', '2_total_fee', '3_total_fee',  '4_total_fee', 'fea-min']:\n",
    "    get_most.columns = [column,column+'_most']\n",
    "    train = train.merge(get_most,on=column,how='left')\n",
    "    \n",
    "for column in ['1_total_fee', '2_total_fee', '3_total_fee',  '4_total_fee', 'fea-min']:\n",
    "    get_most2.columns = [column,column+'_most2']\n",
    "    train = train.merge(get_most2,on=column,how='left')\n",
    "\n",
    "for column in ['1_total_fee', '2_total_fee', '3_total_fee',  '4_total_fee', 'pay_num','fea-min']:\n",
    "    train[column+'_int'] = train[column].fillna(-1).astype('int')\n",
    "    train[column+'_int_last'] = train[column+'_int']%10 #last int \n",
    "    train[column+'_decimal'] = round(((train[column]-train[column+'_int'])*100).fillna(-1)).astype('int')    #decimal\n",
    "    train[column+'_decimal_is_0'] = (train[column+'_decimal']==0).astype('int')\n",
    "    train[column+'_decimal_is_5'] = (train[column+'_decimal']%5==0).astype('int') \n",
    "    train[column+'_decimal_last'] = train[column+'_decimal']%10\n",
    "    train[column+'_decimal_last2'] = train[column+'_decimal']//5 \n",
    "    train[column+'_extra_fee'] = ((train[column]*100)-600)%1000\n",
    "    train[column+'_27perMB'] = ((train[column+'_extra_fee']%27 == 0)&(train[column+'_extra_fee'] != 0)).astype('int')\n",
    "    train[column+'_15perMB'] = ((train[column+'_extra_fee']%15 == 0)&(train[column+'_extra_fee'] != 0)).astype('int')\n",
    "    train = one_hot_encoder(train,column,n=2000,nan_as_category=True)\n",
    "\n",
    "train['pay_num_last2'] = train['pay_num_int']%100  \n",
    "train['former_complaint_fee_last2'] = round(train['former_complaint_fee'])%100      \n",
    "    \n",
    "\n",
    "train['4-fea-dealta'] = round((train['4_total_fee'] - train['3_total_fee'])*100).fillna(999999.9).astype('int')\n",
    "train['3-fea-dealta'] = round((train['3_total_fee'] - train['2_total_fee'])*100).fillna(999999.9).astype('int')\n",
    "train['2-fea-dealta'] = round((train['2_total_fee'] - train['1_total_fee'])*100).fillna(999999.9).astype('int')\n",
    "train['1-fea-dealta'] = round((train['4_total_fee'] - train['1_total_fee'])*100).fillna(999999.9).astype('int')  \n",
    "train['1-3-fea-dealta'] = round((train['3_total_fee'] - train['1_total_fee'])*100).fillna(999999.9).astype('int') \n",
    "train['1-min-fea-dealta'] = round((train['1_total_fee'] - train['fea-min'])*100).fillna(999999.9).astype('int') \n",
    "\n",
    "for column in ['4-fea-dealta', '3-fea-dealta', '2-fea-dealta', '1-fea-dealta','1-3-fea-dealta','1-min-fea-dealta']:\n",
    "    train[column+'_is_0'] = (train[column]==0).astype('int')\n",
    "    train[column+'_is_6000'] = ((train[column]%6000 == 0)&(train[column] != 0)).astype('int') \n",
    "    train[column+'_is_5'] = ((train[column]%5 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_10'] = ((train[column]%10 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_15'] = ((train[column]%15 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_27'] = ((train[column]%27 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_30'] = ((train[column]%30 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_50'] = ((train[column]%50 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_100'] = ((train[column]%100 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_500'] = ((train[column]%500 == 0)&(train[column] != 0)).astype('int')\n",
    "\n",
    "for column in ['month_traffic', 'last_month_traffic', 'local_trafffic_month']:\n",
    "    train[column+'_is_int'] = ((train[column]%1 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_512'] = ((train[column]%512 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_50'] = ((train[column]%50 == 0)&(train[column] != 0)).astype('int')\n",
    "    train[column+'_is_double'] = ((train[column]%512%50 == 0)&(train[column] != 0)&(train[column+'_is_512'] == 0)&(train[column+'_is_50'] == 0)).astype('int')\n",
    "    train = one_hot_encoder(train,column,n=2000,nan_as_category=True)\n",
    "    \n",
    "train['service12'] = train['service2_caller_time']+train['service1_caller_time']\n",
    "for column in ['local_caller_time', 'service1_caller_time', 'service2_caller_time','service12']:\n",
    "    train[column+'_decimal'] =  round(((round(train[column])- train[column])*60)).astype('int')\n",
    "    train[column+'_decimal_is_int'] = ((train[column+'_decimal']==0)&(train[column] != 0)).astype('int')\n",
    "\n",
    "train = one_hot_encoder(train,'online_time',n=5000,nan_as_category=True)\n",
    "train = one_hot_encoder(train,'contract_time',n=5000,nan_as_category=True) \n",
    "\n",
    "print(train.shape)\n",
    "train = one_hot_encoder(train,'contract_type',n=1,nan_as_category=True) \n",
    "\n",
    "\n",
    "\n",
    "#lable 映射 \n",
    "train['current_service'] = train['current_service'].map(current_service2label)\n",
    "\n",
    "\n",
    "train['age'] = train['age'].fillna(-20)\n",
    "train['cut_age'] = train['age'].apply(lambda x: int(x/10))\n",
    "train['cut_online'] = (train['online_time'] / 12).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "train['4-fea-dealta'] = train['4_total_fee'] - train['3_total_fee']\n",
    "train['3-fea-dealta'] = train['3_total_fee'] - train['2_total_fee']\n",
    "train['2-fea-dealta'] = train['2_total_fee'] - train['1_total_fee']\n",
    "train['1-fea-dealta'] = train['4_total_fee'] - train['1_total_fee']\n",
    "\n",
    "train['4-fea-dealta_'] = train['4_total_fee'] / (train['3_total_fee']+0.00001)\n",
    "train['3-fea-dealta_'] = train['3_total_fee'] / (train['2_total_fee']+0.00001)\n",
    "train['2-fea-dealta_'] = train['2_total_fee'] / (train['1_total_fee']+0.00001)\n",
    "train['1-fea-dealta_'] = train['4_total_fee'] / (train['1_total_fee']+0.00001)\n",
    "train['pay_num-dealta_'] = train['pay_num'] / (train['1_total_fee']+0.00001)\n",
    "\n",
    "\n",
    "\n",
    "train['month_traffic_delata'] = train['month_traffic'] - train['last_month_traffic']\n",
    "train['month_traffic_delata_'] = train['month_traffic'] / (train['last_month_traffic']+0.00001)\n",
    "train['2month_traffic_sum'] = train['month_traffic'] + train['last_month_traffic']\n",
    "train['add_month_traffic'] = train['month_traffic'] - train['local_trafffic_month']\n",
    "train['add_month_traffic_'] = train['month_traffic'] / (train['local_trafffic_month']+0.00001)\n",
    "\n",
    "train['service1_caller_time_delata'] = train['service1_caller_time'] / (train['service2_caller_time']+0.00001)\n",
    "train['service1_caller_time_delata2'] = train['service1_caller_time'] / (train['local_caller_time']+0.00001)\n",
    "train['service2_caller_time_delata_'] = train['service2_caller_time'] / (train['local_caller_time']+0.00001)\n",
    "train['local_caller_time_reatio'] = train['local_caller_time']/(train['service1_caller_time']+train['service2_caller_time']+0.00001)\n",
    "\n",
    "train['div_online_time_contract'] = train['contract_time'] / (train['online_time']+0.00001)\n",
    "train['div_online_time_contract'] = train['contract_time'] - train['online_time']\n",
    "\n",
    "\n",
    "train['div_former_complaint_num'] = train['former_complaint_num'] / (train['pay_times']+0.00001)\n",
    "train['div_former_complaint_num'] = train['former_complaint_num'] - train['pay_times']\n",
    "\n",
    "\n",
    "train['fea-sum'] = train[[str(1+i) +'_total_fee' for i in range(4)]].sum(axis = 1)\n",
    "train['fea-var'] = train[[str(1+i) +'_total_fee' for i in range(4)]].var(axis = 1)\n",
    "train['fea-max'] = train[[str(1+i) +'_total_fee' for i in range(4)]].max(axis = 1)\n",
    "train['fea-min'] = train[[str(1+i) +'_total_fee' for i in range(4)]].min(axis = 1)\n",
    "train['fea-mean4'] = train[[str(1+i) +'_total_fee' for i in range(4)]].sum(axis = 1)\n",
    "train['fea-mean3'] = train[[str(1+i) +'_total_fee' for i in range(3)]].sum(axis = 1)\n",
    "train['fea-mean2'] = train[[str(1+i) +'_total_fee' for i in range(2)]].sum(axis = 1)\n",
    "train['fea-extra'] = train['fea-sum']-4*train['fea-min']\n",
    "train['1_total_fee_extra_for_min'] = train['1_total_fee']-train['fea-min']\n",
    "train['fea_unum'] = train[['1_total_fee','2_total_fee','3_total_fee', '4_total_fee']].nunique(axis=1)\n",
    "\n",
    "train['call_time_sum'] = train[call_time].sum(axis = 1)\n",
    "train['call_time_var'] = train[call_time].var(axis = 1)\n",
    "train['call_time_min'] = train[call_time].min(axis = 1)\n",
    "train['call_time_max'] = train[call_time].max(axis = 1)\n",
    "\n",
    "train['traffic_sum'] = train[traffic].sum(axis = 1)\n",
    "train['traffic_var'] = train[traffic].var(axis = 1)\n",
    "train['traffic_min'] = train[traffic].min(axis = 1)\n",
    "train['traffic_max'] = train[traffic].max(axis = 1)\n",
    "\n",
    "\n",
    "train['average_pay'] = train['pay_num'] / train['pay_times']\n",
    "\n",
    "\n",
    "train['div_traffic_price_2'] = train['last_month_traffic']/ 1000 / train['2_total_fee']\n",
    "train['div_traffic_price_3']  = train['local_trafffic_month']/ 1000 / train['1_total_fee']\n",
    "train['div_add_month_traffic_price']  = train['add_month_traffic']/ 1000 / train['1_total_fee']\n",
    "train['div_local_caller_time_price']  = train['local_trafffic_month'] / 1000/ train['1_total_fee']\n",
    "\n",
    "\n",
    "train['1-min-fea-dealta_div'] = train['1-min-fea-dealta']/(train['service1_caller_time']+0.0001)\n",
    "train['div_service1_caller_time_price']  = train['service1_caller_time'] / train['1_total_fee']\n",
    "train['div_local_caller_time']  = train['local_caller_time'] / train['1_total_fee']\n",
    "train['div_call_time_sum_price']  = train['call_time_sum'] / train['1_total_fee']\n",
    "train['1_total_fee_maybe_real_calller'] = train['1_total_fee']- train['service1_caller_time']*0.15\n",
    "train['1_total_fee_maybe_real_calller2'] = train['1_total_fee']- train['service1_caller_time']*0.1\n",
    "train['1_total_fee_extra_for_min_caller_time'] = train['1_total_fee_extra_for_min']/(train['service1_caller_time']+0.001)\n",
    "\n",
    "train['div_service1_caller_time'] = train['service1_caller_time']/train['last_month_traffic']\n",
    "train['div_local_caller_time'] = train['local_caller_time']/train['last_month_traffic']\n",
    "train['div_local_caller_time2'] = train['local_caller_time']/train['month_traffic']\n",
    "\n",
    "\n",
    "train['avg_complain_fee'] = train['former_complaint_fee'] / (train['former_complaint_num'] + 0.000000001)\n",
    "\n",
    "\n",
    "result = []\n",
    "\n",
    "result.append(get_feat_ngroup(train,['cut_age','gender']))\n",
    "for size_feat in ['1_total_fee','2_total_fee','3_total_fee', '4_total_fee','pay_num',\n",
    "'last_month_traffic','month_traffic','local_trafffic_month',\n",
    " 'local_caller_time','service1_caller_time','service2_caller_time']:\n",
    "    result.append(get_feat_size(train,[size_feat]))\n",
    "    \n",
    "    \n",
    "result.append(get_feat_stat_feat(train, ['contract_type'], ['1_total_fee'], ['max']))\n",
    "result.append(get_feat_stat_feat(train, ['contract_type'], ['2_total_fee'], ['mean']))\n",
    "result.append(get_feat_stat_feat(train, ['contract_type'], ['last_month_traffic'], ['var','mean']))\n",
    "result.append(get_feat_stat_feat(train, ['contract_type'], ['call_time_sum'], ['mean']))\n",
    "\n",
    "for base_feat in [['contract_type']]:\n",
    "    for other_feat in ['1_total_fee',  'pay_num',\n",
    "                         'month_traffic', 'last_month_traffic', 'local_trafffic_month', \n",
    "                         'local_caller_time', 'service1_caller_time', 'service2_caller_time',\n",
    "                       ]:\n",
    "        stat_list = ['mean']\n",
    "        tmp = get_feat_stat_feat(train,base_feat,[other_feat],stat_list=stat_list)\n",
    "        name = tmp.columns[0]\n",
    "        train[name] = tmp\n",
    "        train[name+'_comp'] = train[other_feat].values-train[name].values\n",
    "\n",
    "\n",
    "train['1_total_fee_ratio'] = train['1_total_fee']/(train['fea-sum']+0.000001)\n",
    "train['3_total_fee_ratio'] = train['3_total_fee']/(train['fea-sum']+0.000001)\n",
    "train['call_time_sum_ratio'] = train['call_time_sum']/(train['traffic_sum']+0.000001) \n",
    "train['call_time_sum_ratio2'] = train['call_time_sum']/(train['fea-sum']+0.000001) \n",
    "train['traffic_sum_ratio1'] = train['traffic_sum']/(train['fea-sum']+0.000001) \n",
    "\n",
    "####################################lgb和metric函数###################################################\n",
    "\n",
    "def f1_score_vali(preds, data_vali):\n",
    "    labels = data_vali.get_label()\n",
    "    preds = np.argmax(preds.reshape(11, -1),axis=0)\n",
    "    score_vali = f1_score(y_true=labels,y_pred=preds,average='macro')\n",
    "    return 'macro_f1_score', score_vali, True\n",
    "\n",
    "def evaluate_macroF1_lgb(data_vali, preds):  \n",
    "    labels = data_vali.astype(int)\n",
    "    preds = np.array(preds)\n",
    "    preds = np.argmax(preds,axis=1)\n",
    "    score_vali = f1_score(y_true=labels,y_pred=preds,average='macro')\n",
    "    return  score_vali\n",
    "\n",
    "def kfold_lightgbm(params,df, predictors,target,num_folds, stratified = True,\n",
    "                   objective='', metrics='',debug= False,\n",
    "                   feval = f1_score_vali, early_stopping_rounds=100, num_boost_round=100, verbose_eval=50, categorical_features=None,sklearn_mertric = evaluate_macroF1_lgb ):\n",
    "\n",
    "    lgb_params = params\n",
    "    \n",
    "    train_df = df[df[target].notnull()]\n",
    "    test_df = df[df[target].isnull()]\n",
    "    \n",
    "    # Divide in training/validation and test data\n",
    "    print(\"Starting LightGBM. Train shape: {}, test shape: {}\".format(train_df[predictors].shape, test_df[predictors].shape))\n",
    "    del df\n",
    "    gc.collect()\n",
    "    # Cross validation model\n",
    "    if stratified:\n",
    "        folds = StratifiedKFold(n_splits= num_folds, shuffle=True, random_state=1234)\n",
    "    else:\n",
    "        folds = KFold(n_splits= num_folds, shuffle=True, random_state=1234)\n",
    "#    folds = GroupKFold(n_splits=5)\n",
    "    # Create arrays and dataframes to store results\n",
    "    oof_preds = np.zeros((train_df.shape[0],11))\n",
    "    sub_preds = np.zeros((test_df.shape[0],11))\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    feats = predictors\n",
    "    cv_resul = []\n",
    "    '''\n",
    "    perm = [i for i in range(len(train_df))]\n",
    "    perm = pd.DataFrame(perm)\n",
    "    perm.columns = ['index_']\n",
    "\n",
    "    for n_fold in range(5):\n",
    "        train_idx = np.array(perm[train_df['cv'] != n_fold]['index_'])\n",
    "        valid_idx = np.array(perm[train_df['cv'] == n_fold]['index_'])\n",
    "    '''\n",
    "    for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_df[feats], train_df[target])):\n",
    "        if (USE_KFOLD == False) and (n_fold == 1):\n",
    "            break\n",
    "        train_x, train_y = train_df[feats].iloc[train_idx], train_df[target].iloc[train_idx]\n",
    "        valid_x, valid_y = train_df[feats].iloc[valid_idx], train_df[target].iloc[valid_idx]\n",
    "\n",
    "        train_x = pd.concat([train_x,train_old[feats]])\n",
    "        train_y = pd.concat([train_y,train_old[target]])\n",
    "\n",
    "        train_y_t = train_y.values\n",
    "        valid_y_t = valid_y.values\n",
    "        print(train_y_t)\n",
    "        xgtrain = lgb.Dataset(train_x.values, label = train_y_t,\n",
    "                              feature_name=predictors,\n",
    "                              categorical_feature=categorical_features\n",
    "                              )\n",
    "        xgvalid = lgb.Dataset(valid_x.values, label = valid_y_t,\n",
    "                              feature_name=predictors,\n",
    "                              categorical_feature=categorical_features\n",
    "                              )\n",
    "\n",
    "        clf = lgb.train(lgb_params, \n",
    "                         xgtrain, \n",
    "                         valid_sets=[xgvalid],#, xgtrain], \n",
    "                         valid_names=['valid'],#,'train'], \n",
    "                         num_boost_round=num_boost_round,\n",
    "                         early_stopping_rounds=early_stopping_rounds,\n",
    "                         verbose_eval=verbose_eval, \n",
    "#                         feval=feval\n",
    "                         )\n",
    "\n",
    "\n",
    "\n",
    "        oof_preds[valid_idx] = clf.predict(valid_x, num_iteration=clf.best_iteration)\n",
    "        sub_preds += clf.predict(test_df[feats], num_iteration=clf.best_iteration)/ folds.n_splits\n",
    "\n",
    "\n",
    "        gain = clf.feature_importance('gain')\n",
    "        fold_importance_df = pd.DataFrame({'feature':clf.feature_name(),\n",
    "                                           'split':clf.feature_importance('split'),\n",
    "                                           'gain':100*gain/gain.sum(),\n",
    "                                           'fold':n_fold,                        \n",
    "                                           }).sort_values('gain',ascending=False)\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        \n",
    "        result = evaluate_macroF1_lgb(valid_y, oof_preds[valid_idx])\n",
    "#        result = clf.best_score['valid']['macro_f1_score']\n",
    "        print('Fold %2d macro-f1 : %.6f' % (n_fold + 1, result))\n",
    "        cv_resul.append(round(result,5))\n",
    "        gc.collect()\n",
    "\n",
    "    score = 'model_1'\n",
    "    #score = np.array(cv_resul).mean()\n",
    "    if USE_KFOLD:\n",
    "        #print('Full f1 score %.6f' % score)\n",
    "        for i in range(11):\n",
    "            train_df[\"class_\" + str(i)] = oof_preds[:,i]\n",
    "            test_df[\"class_\" + str(i)] = sub_preds[:,i]\n",
    "        train_df[['user_id'] + [\"class_\" + str(i) for i in range(11)]].to_csv('./cv/val_prob_{}.csv'.format(score), index= False, float_format = '%.4f')\n",
    "        test_df[['user_id'] + [\"class_\" + str(i) for i in range(11)]].to_csv('./cv/sub_prob_{}.csv'.format(score), index= False, float_format = '%.4f')   \n",
    "        oof_preds = [np.argmax(x)for x in oof_preds]\n",
    "        sub_preds = [np.argmax(x)for x in sub_preds]    \n",
    "        train_df[target] = oof_preds\n",
    "        test_df[target] = sub_preds\n",
    "        print(test_df[target].mean())\n",
    "        train_df[target] = oof_preds\n",
    "        train_df[target] = train_df[target].map(label2current_service)\n",
    "        test_df[target] = sub_preds\n",
    "        test_df[target] = test_df[target].map(label2current_service)\n",
    "        print('all_cv', cv_resul)\n",
    "\n",
    "        train_df[['user_id', target]].to_csv('./sub/val_{}.csv'.format(score), index= False)\n",
    "        test_df[['user_id', target]].to_csv('./sub/sub_{}.csv'.format(score), index= False)\n",
    "        print(\"test_df mean:\")\n",
    "    \n",
    "    display_importances(feature_importance_df,score)\n",
    "\n",
    "\n",
    "\n",
    "def display_importances(feature_importance_df_,score):\n",
    "    ft = feature_importance_df_[[\"feature\", \"split\",\"gain\"]].groupby(\"feature\").mean().sort_values(by=\"gain\", ascending=False)\n",
    "    print(ft.head(60))\n",
    "    ft.to_csv('importance_lightgbm_{}.csv'.format(score),index=True)\n",
    "    cols = ft[:40].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "\n",
    "\n",
    "####################################计算#################################################################\n",
    "\n",
    "\n",
    "params = {\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_class':11,\n",
    "    'boosting_type': 'gbdt', \n",
    "    'objective': 'multiclass',\n",
    "    'feature_fraction': 0.7,\n",
    "    'learning_rate': 0.02,\n",
    "    'bagging_fraction': 0.7,\n",
    "    #'bagging_freq': 2,\n",
    "    'num_leaves': 64,\n",
    "    'max_depth': -1, \n",
    "    'num_threads': 16, \n",
    "    'seed': 2018, \n",
    "    'verbose': -1,\n",
    "    #'is_unbalance':True,\n",
    "    }\n",
    "\n",
    "\n",
    "categorical_columns = [\n",
    "    'contract_type', \n",
    "    'net_service',\n",
    "    'gender']\n",
    "for feature in categorical_columns:\n",
    "    print(f'Transforming {feature}...')\n",
    "    encoder = LabelEncoder()    \n",
    "    train[feature] = encoder.fit_transform(train[feature].astype(str))    \n",
    "\n",
    "\n",
    "x = []\n",
    "no_use = ['current_service', 'user_id','group',\n",
    " \n",
    "] + x\n",
    "\n",
    "                                         \n",
    "\n",
    "\n",
    "categorical_columns = []\n",
    "all_data_frame = []\n",
    "all_data_frame.append(train)\n",
    "\n",
    "for aresult in result:\n",
    "    all_data_frame.append(aresult)\n",
    "    \n",
    "train = concat(all_data_frame)\n",
    "feats = [f for f in train.columns if f not in no_use]\n",
    "categorical_columns = [f for f in categorical_columns if f not in no_use]\n",
    "\n",
    "train_old = train.iloc[shape1:shape2]\n",
    "train = train.iloc[:shape1]\n",
    "#train = train[train.service_type!=1]\n",
    "#train_old = train_old[train_old.service_type!=1]\n",
    "clf = kfold_lightgbm(params,train,feats,'current_service' ,5 , num_boost_round=4000, categorical_features=categorical_columns)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
